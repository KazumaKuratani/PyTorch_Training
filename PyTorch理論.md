# PyTroch理論
## ニューラルネットワークの定義
### 自作のクラスを作らない方法(nn.Sequential)
nn.Sequentialは、層(レイヤー)を直列に並べるだけでネットワークが作れる便利なコンテナ。  
なぜNNではクラスを使うのか？→NNでは計算ルールだけでなく"重みを記憶"する必要があるため内部データ(変数)を保持できるクラスを使う。  

nn.～：ドット記法、nnという名前のモジュールの中にある～というクラス(設計図)を使うという意味。nn.Linear()だとnnの中にあるLinearクラスを使用している。  

Sequential(～)：他の部品を中に入れるためのコンテナクラスのこと。これらは内部でリストのような順番付きのデータ構造に格納する。基底クラス(nn.Module)→コンテナクラス(nn.Sequential)→部品(ファクトリ)クラス(nn.Linear)  
NN = nn.Sequential(...) と定義した後、NN(x) と書くだけでなぜ「関数」のように動くのか？→PyTorchのすべての部品の親であるnn.Moduleには最初から__call__が定義されている。クラスの中に__call__という名前のメソッドを定義すると、そのクラスから作ったオブジェクトを"関数のように呼び出せる"ようになる。  
つまり、nn = NN()とするとnn()のように呼び出せる。

**デメリット**：一本道しか作れないため「途中でデータを分岐させる」「２つの入力を合流させる」といった複雑なことはできない


### 自作のクラスを使う方法
class(親クラス):～で親クラス(基底クラス)を継承する。PyTorchでは**nn.Modeule**という親クラスを引き継ぐことで様々な機能が自動で手に入る。以下のような機能が自動で手に入る。  
・parameters(): ネットワーク内のすべての重みを自動でリストアップしてくれる機能。  
・to(device): モデルをごっそりGPUに転送する機能。  
・train() / eval(): 学習モードと評価モードを切り替える機能。    
・**重みの自動更新**: optimizer と連携して、勾配の更新を自動で行ってくれる機能。  

def__init__(self):　　
　　　super().__init__() 

・　super():自分の親(nn.Module)を指す  
.　__init__():初期化する。大事な準備を先に済ませる。  
これらを行うことによって自分の設定を始める前に親クラスが代々引き継いできた大事な準備を先に済ませておく。


### DataLoader と Dataset の関係
Datasetは1サンプルずつ作る
DataLoaderはそれをまとめて作る
DataLoader は「Dataset を、順番・まとめ方・並列性を制御して供給する装置」
num_workersについて
環境	推奨
CPUのみ	0〜2
GPU	CPUコア数の半分くらい
